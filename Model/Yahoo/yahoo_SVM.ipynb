{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVMs / KNNs on yahoo datasets "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/irisliu/anaconda2/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/home/irisliu/anaconda2/lib/python2.7/site-packages/sklearn/grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n",
      "/home/irisliu/anaconda2/lib/python2.7/site-packages/sklearn/lda.py:6: DeprecationWarning: lda.LDA has been moved to discriminant_analysis.LinearDiscriminantAnalysis in 0.17 and will be removed in 0.19\n",
      "  \"in 0.17 and will be removed in 0.19\", DeprecationWarning)\n",
      "/home/irisliu/anaconda2/lib/python2.7/site-packages/sklearn/learning_curve.py:23: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the functions are moved. This module will be removed in 0.20\n",
      "  DeprecationWarning)\n",
      "/home/irisliu/anaconda2/lib/python2.7/site-packages/sklearn/qda.py:6: DeprecationWarning: qda.QDA has been moved to discriminant_analysis.QuadraticDiscriminantAnalysis in 0.17 and will be removed in 0.19.\n",
      "  \"in 0.17 and will be removed in 0.19.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "\n",
    "#from tabulate import tabulate\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter, defaultdict\n",
    "from sklearn import *\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.cross_validation import cross_val_score, train_test_split, KFold\n",
    "#from gensim.models.word2vec import Word2Vec \n",
    "\n",
    "np.random.seed(1337)\n",
    "\n",
    "MAX_SEQUENCE_LENGTH = 1000\n",
    "MAX_NB_WORDS = 20000\n",
    "EMBEDDING_DIM = 100\n",
    "VALIDATION_SPLIT = 0.1\n",
    "DROP_OUT = 0.3\n",
    "Nb_EPOCH = 30\n",
    "BATCH_SIZE = 50\n",
    "Classes = 180\n",
    "\n",
    "GLOVE_DIR = './glove.6B/'\n",
    "FILENAME = 'glove.6B.' + str(EMBEDDING_DIM) + 'd.txt'\n",
    "TEXT_DATA_DIR = './yahoo_' + str(Classes) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 112500 texts.\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-02731b933479>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m                 \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Found %s texts.'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mtexts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "texts = []  # list of text samples\n",
    "labels_index = {}  # dictionary mapping label name to numeric id\n",
    "labels = []  # list of label ids\n",
    "for name in sorted(os.listdir(TEXT_DATA_DIR)):\n",
    "    path = os.path.join(TEXT_DATA_DIR, name)\n",
    "    if os.path.isdir(path):\n",
    "        label_id = len(labels_index)\n",
    "        labels_index[name] = label_id\n",
    "        for fname in sorted(os.listdir(path)):\n",
    "            if fname.isdigit():\n",
    "                fpath = os.path.join(path, fname)\n",
    "                if sys.version_info < (3,):\n",
    "                    f = open(fpath)\n",
    "                else:\n",
    "                    f = open(fpath, encoding='latin-1')\n",
    "                texts.append(f.read())\n",
    "                f.close()\n",
    "                labels.append(label_id)\n",
    "print('Found %s texts.' % len(texts))\n",
    "texts, labels = np.array(texts), np.array(labels)\n",
    "print (texts.shape, labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Prepare word embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "embeddings_index = {}\n",
    "# fname = os.path.join(GLOVE_DIR, 'glove.twitter.27B.' + str(EMBEDDING_DIM) + 'd.txt')\n",
    "fname = os.path.join(GLOVE_DIR, FILENAME)\n",
    "\n",
    "with open(fname, \"rb\") as lines:\n",
    "    word2vec = {line.split()[0]: np.array(map(float, line.split()[1:]))\n",
    "               for line in lines}\n",
    "    \n",
    "f = open(fname)\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))\n",
    "print ('Word2Vec: %s' % len(word2vec))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Implement  an embedding vector "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MeanEmbeddingVectorizer(object):\n",
    "    def __init__(self, word2vec):\n",
    "        self.word2vec = word2vec\n",
    "        self.dim = len(word2vec.itervalues().next())\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        return self \n",
    "\n",
    "    def transform(self, X):\n",
    "        return np.array([\n",
    "            np.mean([self.word2vec[w] for w in words if w in self.word2vec] \n",
    "                    or [np.zeros(self.dim)], axis=0)\n",
    "            for words in X\n",
    "        ])\n",
    "    \n",
    "class TfidfEmbeddingVectorizer(object):\n",
    "    def __init__(self, word2vec):\n",
    "        self.word2vec = word2vec\n",
    "        self.word2weight = None\n",
    "        self.dim = len(word2vec.itervalues().next())\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        tfidf = TfidfVectorizer(analyzer=lambda x: x)\n",
    "        tfidf.fit(X)\n",
    "        # if a word was never seen - it must be at least as infrequent\n",
    "        # as any of the known words - so the default idf is the max of \n",
    "        # known idf's\n",
    "        max_idf = max(tfidf.idf_)\n",
    "        self.word2weight = defaultdict(\n",
    "            lambda: max_idf, \n",
    "            [(w, tfidf.idf_[i]) for w, i in tfidf.vocabulary_.items()])\n",
    "    \n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return np.array([\n",
    "                np.mean([self.word2vec[w] * self.word2weight[w]\n",
    "                         for w in words if w in self.word2vec] or\n",
    "                        [np.zeros(self.dim)], axis=0)\n",
    "                for words in X\n",
    "            ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Create model structure (SVM/ KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cntvect = feature_extraction.text.CountVectorizer(stop_words='english')                                                    \n",
    "trainX, valX, trainY, valY = train_test_split(texts, labels, test_size=VALIDATION_SPLIT) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svc_glove27B = Pipeline([(\"count_vectorizer\", MeanEmbeddingVectorizer(embeddings_index)), (\"linear svc\", SVC(kernel=\"linear\"))])\n",
    "knn_glove27B = Pipeline([(\"count_vectorizer\", MeanEmbeddingVectorizer(embeddings_index)), (\"KNN\", neighbors.KNeighborsClassifier())])\n",
    "svc_glove27B_tfidf = Pipeline([(\"tfidf_vectorizer\", TfidfEmbeddingVectorizer(embeddings_index)), (\"linear svc\", SVC(kernel=\"linear\"))])\n",
    "knn_glove27B_tfidf = Pipeline([(\"tfidf_vectorizer\", TfidfEmbeddingVectorizer(embeddings_index)), (\"KNN\", neighbors.KNeighborsClassifier())])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_models = [\n",
    "    (\"SVM\", svc_glove27B),\n",
    "    (\"KNN\", knn_glove27B),\n",
    "    (\"SVM-TFIDF\", svc_glove27B_tfidf),\n",
    "    (\"KNN-TFIDF\", knn_glove27B_tfidf),  \n",
    "]\n",
    "scores = sorted([(name, cross_val_score(model, trainX, trainY, cv=5).mean()) \n",
    "                 for name, model in all_models], \n",
    "                key=lambda (_, x): -x)\n",
    "\n",
    "print (scores)\n",
    "#print tabulate(scores, floatfmt=\".4f.79055799899004708), ('KNN'\", headers=(\"model\", 'score'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def benchmark(model, X, y):\n",
    "    skf = KFold(len(X), n_folds=5, shuffle=True, random_state= 1337)\n",
    "    scores = []\n",
    "    for train, test in skf:\n",
    "        X_train, X_test = X[train], X[test]\n",
    "        y_train, y_test = y[train], y[test]\n",
    "        scores.append(accuracy_score(model.fit(X_train, y_train).predict(X_test), y_test))\n",
    "    return np.mean(scores)\n",
    "\n",
    "#benchmark(model, texts, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "table = []\n",
    "start = time.time()\n",
    "for name, model in all_models:\n",
    "    table.append({'model': name, \n",
    "                    'accuracy': benchmark(model, texts, labels)})\n",
    "print (\"Total run time: \", time.time()-start)\n",
    "df = pd.DataFrame(table)\n",
    "print (df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# classes: 5\n",
    " accuracy      model\n",
    "0  0.765992        SVM\n",
    "1  0.752564        KNN\n",
    "2  0.768358  SVM-TFIDF\n",
    "3  0.758482  KNN-TFIDF\n",
    "\n",
    "# classes: 10\n",
    "\n",
    " accuracy      model\n",
    "0  0.596764        SVM\n",
    "1  0.622618        KNN\n",
    "2  0.603283  SVM-TFIDF\n",
    "3  0.624864  KNN-TFIDF\n",
    "\n",
    "# classes: 20\n",
    "Total run time:  918.678102016\n",
    "   accuracy      model\n",
    "0  0.467512        SVM\n",
    "1  0.467318        KNN\n",
    "2  0.471844  SVM-TFIDF\n",
    "3  0.475389  KNN-TFIDF\n",
    "\n",
    "\n",
    "# classes: 30\n",
    "Total run time:  1777.46248698\n",
    "   accuracy      model\n",
    "0  0.394013        SVM\n",
    "1  0.429211        KNN\n",
    "2  0.403931  SVM-TFIDF\n",
    "3  0.428364  KNN-TFIDF\n",
    "\n",
    "\n",
    "# classes: 40\n",
    "Total run time:  12126.748764\n",
    "   accuracy      model\n",
    "0  0.471411        SVM\n",
    "1  0.483445        KNN\n",
    "2  0.476590  SVM-TFIDF\n",
    "3  0.483315  KNN-TFIDF\n",
    "\n",
    "# classes: 60\n",
    "Total run time:  4297.12801099\n",
    "   accuracy      model\n",
    "0  0.336113        SVM\n",
    "1  0.336112        KNN\n",
    "2  0.340016  SVM-TFIDF\n",
    "3  0.335994  KNN-TFIDF\n",
    "\n",
    "\n",
    "# classes: 120\n",
    "Total run time:  42448.8118892\n",
    "   accuracy      model\n",
    "0  0.294859        SVM\n",
    "1  0.290941        KNN\n",
    "2  0.298249  SVM-TFIDF\n",
    "3  0.292060  KNN-TFIDF\n",
    "\n",
    "\n",
    "# classes: 180\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# classes: 280\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
