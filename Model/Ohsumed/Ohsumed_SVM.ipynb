{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVMs / KNNs on Ohsumed datasets "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/sklearn/lda.py:4: DeprecationWarning: lda.LDA has been moved to discriminant_analysis.LinearDiscriminantAnalysis in 0.17 and will be removed in 0.19\n",
      "  \"in 0.17 and will be removed in 0.19\", DeprecationWarning)\n",
      "/usr/local/lib/python2.7/site-packages/sklearn/qda.py:4: DeprecationWarning: qda.QDA has been moved to discriminant_analysis.QuadraticDiscriminantAnalysis in 0.17 and will be removed in 0.19.\n",
      "  \"in 0.17 and will be removed in 0.19.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "\n",
    "#from tabulate import tabulate\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter, defaultdict\n",
    "from sklearn import *\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.cross_validation import cross_val_score, train_test_split, KFold\n",
    "#from gensim.models.word2vec import Word2Vec \n",
    "\n",
    "np.random.seed(1337)\n",
    "\n",
    "MAX_SEQUENCE_LENGTH = 1000\n",
    "MAX_NB_WORDS = 20000\n",
    "EMBEDDING_DIM = 100\n",
    "VALIDATION_SPLIT = 0.1\n",
    "DROP_OUT = 0.3\n",
    "Nb_EPOCH = 10\n",
    "BATCH_SIZE = 10\n",
    "Classes = 23\n",
    "\n",
    "GLOVE_DIR = './glove.6B/'\n",
    "FILENAME = 'glove.6B.' + str(EMBEDDING_DIM) + 'd.txt'\n",
    "TEXT_DATA_DIR = './ohsumed_' + str(Classes) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 56984 texts.\n",
      "(56984,) (56984,)\n"
     ]
    }
   ],
   "source": [
    "texts = []  # list of text samples\n",
    "labels_index = {}  # dictionary mapping label name to numeric id\n",
    "labels = []  # list of label ids\n",
    "for name in sorted(os.listdir(TEXT_DATA_DIR)):\n",
    "    path = os.path.join(TEXT_DATA_DIR, name)\n",
    "    if os.path.isdir(path):\n",
    "        label_id = len(labels_index)\n",
    "        labels_index[name] = label_id\n",
    "        for fname in sorted(os.listdir(path)):\n",
    "            if fname.isdigit():\n",
    "                fpath = os.path.join(path, fname)\n",
    "                if sys.version_info < (3,):\n",
    "                    f = open(fpath)\n",
    "                else:\n",
    "                    f = open(fpath, encoding='latin-1')\n",
    "                texts.append(f.read())\n",
    "                f.close()\n",
    "                labels.append(label_id)\n",
    "print('Found %s texts.' % len(texts))\n",
    "texts, labels = np.array(texts), np.array(labels)\n",
    "print (texts.shape, labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Prepare word embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n",
      "Word2Vec: 400000\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = {}\n",
    "# fname = os.path.join(GLOVE_DIR, 'glove.twitter.27B.' + str(EMBEDDING_DIM) + 'd.txt')\n",
    "fname = os.path.join(GLOVE_DIR, FILENAME)\n",
    "\n",
    "with open(fname, \"rb\") as lines:\n",
    "    word2vec = {line.split()[0]: np.array(map(float, line.split()[1:]))\n",
    "               for line in lines}\n",
    "    \n",
    "f = open(fname)\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))\n",
    "print ('Word2Vec: %s' % len(word2vec))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Implement  an embedding vector "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MeanEmbeddingVectorizer(object):\n",
    "    def __init__(self, word2vec):\n",
    "        self.word2vec = word2vec\n",
    "        self.dim = len(word2vec.itervalues().next())\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        return self \n",
    "\n",
    "    def transform(self, X):\n",
    "        return np.array([\n",
    "            np.mean([self.word2vec[w] for w in words if w in self.word2vec] \n",
    "                    or [np.zeros(self.dim)], axis=0)\n",
    "            for words in X\n",
    "        ])\n",
    "    \n",
    "class TfidfEmbeddingVectorizer(object):\n",
    "    def __init__(self, word2vec):\n",
    "        self.word2vec = word2vec\n",
    "        self.word2weight = None\n",
    "        self.dim = len(word2vec.itervalues().next())\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        tfidf = TfidfVectorizer(analyzer=lambda x: x)\n",
    "        tfidf.fit(X)\n",
    "        # if a word was never seen - it must be at least as infrequent\n",
    "        # as any of the known words - so the default idf is the max of \n",
    "        # known idf's\n",
    "        max_idf = max(tfidf.idf_)\n",
    "        self.word2weight = defaultdict(\n",
    "            lambda: max_idf, \n",
    "            [(w, tfidf.idf_[i]) for w, i in tfidf.vocabulary_.items()])\n",
    "    \n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return np.array([\n",
    "                np.mean([self.word2vec[w] * self.word2weight[w]\n",
    "                         for w in words if w in self.word2vec] or\n",
    "                        [np.zeros(self.dim)], axis=0)\n",
    "                for words in X\n",
    "            ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Create model structure (SVM/ KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cntvect = feature_extraction.text.CountVectorizer(stop_words='english')                                                    \n",
    "trainX, valX, trainY, valY = train_test_split(texts, labels, test_size=VALIDATION_SPLIT) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svc_glove27B = Pipeline([(\"count_vectorizer\", MeanEmbeddingVectorizer(embeddings_index)), (\"linear svc\", SVC(kernel=\"linear\"))])\n",
    "knn_glove27B = Pipeline([(\"count_vectorizer\", MeanEmbeddingVectorizer(embeddings_index)), (\"KNN\", neighbors.KNeighborsClassifier())])\n",
    "svc_glove27B_tfidf = Pipeline([(\"tfidf_vectorizer\", TfidfEmbeddingVectorizer(embeddings_index)), (\"linear svc\", SVC(kernel=\"linear\"))])\n",
    "knn_glove27B_tfidf = Pipeline([(\"tfidf_vectorizer\", TfidfEmbeddingVectorizer(embeddings_index)), (\"KNN\", neighbors.KNeighborsClassifier())])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('SVM-TFIDF', 0.18410852636000369), ('SVM', 0.17905892814107549), ('KNN', 0.1040464748596506), ('KNN-TFIDF', 0.10359714898454095)]\n"
     ]
    }
   ],
   "source": [
    "all_models = [\n",
    "    (\"SVM\", svc_glove27B),\n",
    "    (\"KNN\", knn_glove27B),\n",
    "    (\"SVM-TFIDF\", svc_glove27B_tfidf),\n",
    "    (\"KNN-TFIDF\", knn_glove27B_tfidf),  \n",
    "]\n",
    "scores = sorted([(name, cross_val_score(model, trainX, trainY, cv=5).mean()) \n",
    "                 for name, model in all_models], \n",
    "                key=lambda (_, x): -x)\n",
    "\n",
    "print (scores)\n",
    "#print tabulate(scores, floatfmt=\".4f.79055799899004708), ('KNN'\", headers=(\"model\", 'score'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def benchmark(model, X, y):\n",
    "    skf = KFold(len(X), n_folds=5, shuffle=True, random_state= 1337)\n",
    "    scores = []\n",
    "    for train, test in skf:\n",
    "        X_train, X_test = X[train], X[test]\n",
    "        y_train, y_test = y[train], y[test]\n",
    "        scores.append(accuracy_score(model.fit(X_train, y_train).predict(X_test), y_test))\n",
    "    return np.mean(scores)\n",
    "\n",
    "#benchmark(model, texts, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   accuracy      model\n",
      "0  0.179770        SVM\n",
      "1  0.099642        KNN\n",
      "2  0.185140  SVM-TFIDF\n",
      "3  0.101608  KNN-TFIDF\n"
     ]
    }
   ],
   "source": [
    "table = []\n",
    "for name, model in all_models:\n",
    "    table.append({'model': name, \n",
    "                    'accuracy': benchmark(model, texts, labels)})\n",
    "df = pd.DataFrame(table)\n",
    "print (df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-10-110c8fba1649>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-10-110c8fba1649>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    accuracy      model\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "# classes: 5\n",
    "  accuracy      model\n",
    "0  0.556128        SVM\n",
    "1  0.444220        KNN\n",
    "2  0.556128  SVM-TFIDF\n",
    "3  0.448791  KNN-TFIDF\n",
    "# classes: 10\n",
    "  accuracy      model\n",
    "0  0.352544        SVM\n",
    "1  0.253091        KNN\n",
    "2  0.358560  SVM-TFIDF\n",
    "3  0.252541  KNN-TFIDF\n",
    "\n",
    "# classes: 15\n",
    " accuracy      model\n",
    "0  0.244368        SVM\n",
    "1  0.149621        KNN\n",
    "2  0.249224  SVM-TFIDF\n",
    "3  0.149240  KNN-TFIDF\n",
    "\n",
    "# classes: 20\n",
    "   accuracy      model\n",
    "0  0.206701        SVM\n",
    "1  0.112351        KNN\n",
    "2  0.210723  SVM-TFIDF\n",
    "3  0.112782  KNN-TFIDF\n",
    "\n",
    "\n",
    "# classes: 23\n",
    "  accuracy      model\n",
    "0  0.179770        SVM\n",
    "1  0.099642        KNN\n",
    "2  0.185140  SVM-TFIDF\n",
    "3  0.101608  KNN-TFIDF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
